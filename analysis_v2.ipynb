{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib.dates import YearLocator, DateFormatter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from langdetect import detect\n",
    "from wordcloud import WordCloud\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_category_stats(data, col):\n",
    "    '''\n",
    "    Plots bar charts for the mean, median, and sum of ratings grouped by a specified category.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): DataFrame containing the data with columns for categories and ratings.\n",
    "    col (str): Column name to group by (e.g., 'primary_category').\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    '''\n",
    "    # Calculate mean, median, and sum of ratings for each category\n",
    "    category_stats = data.groupby(col)['rating'].agg(['mean', 'median', 'sum']).reset_index()\n",
    "\n",
    "    # Plot the statistics\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=False)\n",
    "\n",
    "    # Mean Ratings\n",
    "    sns.barplot(x=col, y='mean', data=category_stats, palette='viridis', ax=axes[0])\n",
    "    axes[0].set_xlabel('Primary Category')\n",
    "    axes[0].set_ylabel('Mean Rating')\n",
    "    axes[0].set_title(f'Mean Rating by {col}')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    axes[0].set_ylim(0, category_stats['mean'].max() * 1.1)  # Set y-axis limit\n",
    "\n",
    "    # Median Ratings\n",
    "    sns.barplot(x=col, y='median', data=category_stats, palette='viridis', ax=axes[1])\n",
    "    axes[1].set_xlabel('Primary Category')\n",
    "    axes[1].set_ylabel('Median Rating')\n",
    "    axes[1].set_title(f'Median Rating by {col}')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    axes[1].set_ylim(0, category_stats['median'].max() * 1.1)  # Set y-axis limit\n",
    "\n",
    "    # Sum Ratings\n",
    "    sns.barplot(x=col, y='sum', data=category_stats, palette='viridis', ax=axes[2])\n",
    "    axes[2].set_xlabel('Primary Category')\n",
    "    axes[2].set_ylabel('Total Rating')\n",
    "    axes[2].set_title(f'Total Rating by {col}')\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "    axes[2].set_ylim(0, category_stats['sum'].max() * 1.1)  # Set y-axis limit\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'product_info.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m product_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproduct_info.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m t1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreviews_0-250.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# t2 = pd.read_csv(\"reviews_250-500.csv\")\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# t3 = pd.read_csv(\"reviews_1250-end.csv\")\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# t4 = pd.read_csv(\"reviews_500-750.csv\") \u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'product_info.csv'"
     ]
    }
   ],
   "source": [
    "product_df = pd.read_csv(\"product_info.csv\")\n",
    "\n",
    "\n",
    "t1 = pd.read_csv(\"reviews_0-250.csv\")\n",
    "# t2 = pd.read_csv(\"reviews_250-500.csv\")\n",
    "# t3 = pd.read_csv(\"reviews_1250-end.csv\")\n",
    "# t4 = pd.read_csv(\"reviews_500-750.csv\") \n",
    "review_df = t1#pd.concat([t1,t2,t3]).drop(columns='Unnamed: 0') .sort_values(by = 'submission_time')\n",
    "review_df['primary_category'] = review_df.product_id.map(dict(zip(product_df.product_id, product_df.primary_category)))\n",
    "review_df['submission_time'] = pd.to_datetime(review_df['submission_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(product_df.columns )\n",
    "plot_category_stats(product_df, 'primary_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique primary categories\n",
    "categories = product_df.primary_category.unique()\n",
    "\n",
    "# Set up the plotting environment\n",
    "fig, axes = plt.subplots(len(categories), 1, figsize=(14, 2 + 5 * len(categories)))\n",
    "\n",
    "# Ensure axes is always iterable\n",
    "if len(categories) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Loop over each category and plot\n",
    "for ax, category in zip(axes, categories):\n",
    "    product_df_i = product_df[product_df.primary_category == category]\n",
    "    product_df_i = product_df_i.groupby('product_name')[['rating']].mean().reset_index().sort_values(by = 'rating',ascending = False).iloc[:20]\n",
    "    bar_plot = sns.barplot(x='product_name', y='rating', data=product_df_i, palette='viridis', ax=ax)\n",
    "    ax.set_title(f'Ratings by Product for {category}')\n",
    "    ax.set_ylabel(category)  # Set y-label to the current category\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=30, ha='right')  # Rotate x-axis labels for better readability\n",
    "\n",
    "    # Annotate each bar with its height\n",
    "    for p in bar_plot.patches:\n",
    "        height = p.get_height()\n",
    "        ax.annotate(f'{height:.2f}', \n",
    "                    (p.get_x() + p.get_width() / 2., height), \n",
    "                    ha='center', va='center', \n",
    "                    xytext=(0, 2),  # 3 points vertical offset\n",
    "                    textcoords='offset points')\n",
    "\n",
    "# Adjust layout to make room for labels\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=2) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 15 brands by review count\n",
    "top_brand = list(review_df.brand_name.value_counts().iloc[:15].index)\n",
    "top_brand_review_df = review_df[review_df.brand_name.isin(top_brand)]\n",
    "\n",
    "# Convert submission_time to datetime\n",
    "top_brand_review_df['submission_time'] = pd.to_datetime(top_brand_review_df['submission_time'])\n",
    "\n",
    "# Extract the year from submission_time\n",
    "top_brand_review_df['year'] = top_brand_review_df['submission_time'].dt.year\n",
    "\n",
    "# Group by year and brand_name and calculate the mean rating\n",
    "mean_rating_yearly = top_brand_review_df.groupby(['year', 'brand_name'])['rating'].mean().reset_index()\n",
    "\n",
    "# Create the line plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "palette = sns.color_palette(\"tab20\", len(top_brand))  # Use a color palette with 20 distinct colors\n",
    "sns.lineplot(data=mean_rating_yearly, x='year', y='rating', hue='brand_name', palette=palette, marker='o')\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Mean Rating Yearly of Each Brand in Skin Care Category')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mean Rating')\n",
    "# plt.legend(title='Brand', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Label each line with the brand name at the end\n",
    "for brand in top_brand:\n",
    "    brand_data = mean_rating_yearly[mean_rating_yearly['brand_name'] == brand]\n",
    "    plt.text(brand_data['year'].max() + 0.1, \n",
    "             brand_data['rating'].iloc[-1], \n",
    "             brand, \n",
    "             horizontalalignment='left', \n",
    "             size='medium', \n",
    "             color=palette[top_brand.index(brand)])\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(review_df.submission_time, review_df.total_feedback_count.cumsum(), linestyle='-', color='b', label='Total Feedback')\n",
    "plt.plot(review_df.submission_time, review_df.total_neg_feedback_count.cumsum(),linestyle='-', color='r', label='Total Negative Feedback')\n",
    "plt.plot(review_df.submission_time, review_df.total_pos_feedback_count.cumsum(), linestyle='-', color='g', label='Total Positive Feedback')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Cumulative Feedback Over Time')\n",
    "plt.xlabel('Submission Time')\n",
    "plt.ylabel('Cumulative Feedback Count')\n",
    "\n",
    "# Set major locator and formatter for yearly labels\n",
    "plt.gca().xaxis.set_major_locator(YearLocator())\n",
    "plt.gca().xaxis.set_major_formatter(DateFormatter('%Y'))\n",
    "\n",
    "# Rotate x-axis ticks\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_df has column total_neg_feedback_count\ttotal_pos_feedback_count and brand_name \n",
    "# Set up the figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "gb_top_brand_review_df = top_brand_review_df.groupby(['brand_name'])[['total_pos_feedback_count','total_neg_feedback_count']].sum().reset_index()\n",
    "# Plot negative feedback counts\n",
    "sns.barplot(data=gb_top_brand_review_df, y='brand_name', x='total_neg_feedback_count', color='red', label='Negative Feedback', alpha =  0.5)\n",
    "\n",
    "# Plot positive feedback counts\n",
    "sns.barplot(data=gb_top_brand_review_df, y='brand_name', x='total_pos_feedback_count', color='blue', label='Positive Feedback', alpha =  0.5)\n",
    "\n",
    "plt.title('Feedback Counts by Brand')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Brand')\n",
    "plt.legend(title='Feedback Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = review_df.iloc[:2000]\n",
    "def simple_stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "#removing the stopwords\n",
    "#Setting English stopwords\n",
    "stopword_list=nltk.corpus.stopwords.words('english')\n",
    "stop=set(stopwords.words('english'))\n",
    "#Tokenization of text\n",
    "tokenizer=ToktokTokenizer()\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "# Preprocess the data\n",
    "df['review_text'].fillna('', inplace=True)\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)  # Remove non-English characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "# Apply text cleaning\n",
    "df['cleaned_review_text'] = df['review_text'].apply(clean_text)\n",
    "# df['cleaned_review_text']=df['cleaned_review_text'].apply(simple_stemmer) ##########\n",
    "df['cleaned_review_text']=df['cleaned_review_text'].apply(remove_stopwords) ########## remove stop words in English are “the”, “a”, “an”, “so”, “what”.\n",
    "# Function to detect language and filter out non-English reviews\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except LangDetectException:\n",
    "        return False\n",
    "\n",
    "# Filter out non-English reviews\n",
    "df = df[df['cleaned_review_text'].apply(is_english)]\n",
    "\n",
    "# df.to_csv('cleaned_review_text.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute word count for each review\n",
    "df['word_count'] = df['cleaned_review_text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# # Group by rating and compute the average word count\n",
    "word_count_by_rating = df.groupby('rating')['word_count'].mean().reset_index()\n",
    "print(f'the number of word is not correlated with rating')\n",
    "display(word_count_by_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df has column cleaned_review_text and brand_name. I want to find the frequency word in each brand_name\n",
    "from collections import Counter\n",
    "# Create a dictionary to hold word frequencies for each brand\n",
    "brand_word_frequencies = {}\n",
    "\n",
    "# Group by brand_name\n",
    "for brand, group in df.groupby('brand_name'):\n",
    "    # Concatenate all review texts for the current brand\n",
    "    text = ' '.join(group['cleaned_review_text'])\n",
    "    # Split text into words and calculate frequencies\n",
    "    words = text.split()\n",
    "    word_freq = Counter(words)\n",
    "    brand_word_frequencies[brand] = word_freq\n",
    "\n",
    "selected_brand = 'Caudalie'\n",
    "# for selected_brand in top_brand\n",
    "# Get the word frequencies for the selected brand\n",
    "word_freq = brand_word_frequencies.get(selected_brand, {})\n",
    "\n",
    "# Convert to DataFrame for plotting\n",
    "word_freq_df = pd.DataFrame(word_freq.items(), columns=['Word', 'Frequency'])\n",
    "\n",
    "# Plot the top 10 most frequent words\n",
    "df['submission_time'] = pd.to_datetime(df['submission_time'])\n",
    "\n",
    "# Get and format the earliest and latest submission times\n",
    "earliest_time = df['submission_time'].min().strftime('%Y-%m-%d')\n",
    "latest_time = df['submission_time'].max().strftime('%Y-%m-%d')\n",
    "top_words = word_freq_df.nlargest(10, 'Frequency')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Frequency', y='Word', data=top_words)\n",
    "plt.title(f'Top 10 Words for {selected_brand} from {earliest_time} to {latest_time}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the text for each brand\n",
    "brand_texts = {}\n",
    "\n",
    "# Group by brand_name and concatenate review texts\n",
    "for brand, group in df.groupby('brand_name'):\n",
    "    # Concatenate all review texts for the current brand\n",
    "    text = ' '.join(group['cleaned_review_text'])\n",
    "    brand_texts[brand] = text\n",
    "\n",
    "# Define the number of brands to display (adjust as needed)\n",
    "num_brands_to_display = min(len(brand_texts), 10)\n",
    "\n",
    "# Set up the plot\n",
    "fig, axes = plt.subplots(nrows=num_brands_to_display, ncols=1, figsize=(10, 2*num_brands_to_display))\n",
    "axes = axes.flatten()  # Flatten the array of axes\n",
    "\n",
    "# Generate and plot word clouds for each brand\n",
    "for i, (brand, text) in enumerate(list(brand_texts.items())[:num_brands_to_display]):\n",
    "    wordcloud = WordCloud(width=1200, height=600, background_color='white').generate(text)\n",
    "    axes[i].imshow(wordcloud, interpolation='bilinear')\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(brand)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
